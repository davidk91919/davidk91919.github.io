---
layout: post
title: 'why statistics?'
---

고파스를 보다가 통계학은 그냥 데이터 다루는 일을 하는 거 같은데 뭔 학문까지 필요하냐? (이렇게 시비조로 물어보는 글은 아니었음) 라는 질문이 올라와서 댓글을 이러저러하게 달다가, 뭔가 여러가지 생각이 떠올랐고 이들을 정리해보고 싶어서 글을 남긴다.

오늘따라 더위를 먹었는지 머리 아파 죽겠는데, 이해해야하는 부등식을 펼치기가 싫어서 이런 글을 남기는 내 인생이 레전드인듯..

-

1. '통계학이 어떤 학문이고 어떤 문제를 푸는데 필요하냐?'는 질문에 대한 내 대답을 한줄로 말하자면, '통계학은 수학의 언어로 형성된 귀납의 과학이다'쯤 될 거 같다. 우리는 귀납추론에 대한 확실성을 수학의 언어로 정당화하고 싶고 나아가 확실성의 정도를 수치화하고 싶다. 이게 통계학의 출발점이다.

그 확실성의 정도는 확률로 정의될텐데, 확률이라는 도구 혹은 함수를 잘 생각해보면 이건 각 event에 대한 일종의 set function임을 알 수 있다. 그니까 단순한 함수가 아니라는 것. 

또 우리는 어떤 추론의 대상이 수렴하는 평균 뿐 아니라, 그 추론을 위해 사용된 추정량이 얼마나 분산되어 있을지(=많이 분산되어 있다면 그 추정량은 비효율적이라고 생각할 수 있음)에도 관심사가 있다.

추론의 대상들이 확률변수로 추상화된 데이터들의 일종의 적분값으로 정의된다면, 그런 분산은 제곱의 적분값으로 표현이 될텐데,
이 두 가지 논점에서 우리는 왜 메져라는 대상과 메져의 적분이라는 도구가 통계학의 근간을 이루는지 알 수 있음. 

2. 여기까지는 사실 '귀납추론의 수치화를 위한 실해석'에 대한 motivation에 가까울 것이고, 그럼 더 나아가서 통계학이 실제로 왜 필요한지 좀 더 생각을 해보자면..
매우 놀라운 두 가지 정리가 통계학의 핵심을 이룬다- 큰 수의 법칙과 중심극한정리. 특히 중심극한정리는 '잘 추출된' 표본들이 정규분포로 수렴한다는 결과를 제공한다.

여기서 귀납추론을 하는 우리는 최악의 상황을 가정해서 현재까지의 우리의 추론의 확실성을 평가하고자 한다 - 즉, '지금까지의 상황과 정반대의 상황을 가정했을 때, 현재 관찰된 통계량과 그보다 극단적인 값이 발견될 확률은 얼마인가?'라는 것. 
중심극한저일를 통해 충분히 예쁜 상황들에서는 우리는 위의 확률을 매우 간단하게 수치화할 수 있다. 

통계학의 주요 목적 중 하나를 - 귀납추론이 필요한 상황이 있다면 그에 대한 귀무가설과 대립가설을 characterize하고, 그 가설들에 대한 통계량과 필요하다면 통계량에 필요한 reference distribution을 제공하는 데 있다고 말할 수 있을 것이다. 

3. 위까지는 '추론inference'이라는 분과에 대한 통계학의 motivation이라고 할 수 있을 것이다. 즉 위에서 나는, 이미 추정량이 주어졌을 때 그 추정량에 대한 귀납추론을 위해 통계학이 필요하다는 이야기를 하고 싶었다.

그럼 추정량을 만드는 데 있어서 통계학에는 어떤 특질이 있냐? 라는 질문은 자연스럽다. 여기까지 오면 이미 통계학만의 분야라고 하기는 힘들지만 - 그러나 내가 가진 두 가지 정도의 직관을 풀어보고자 한다. 

(1) 먼저 통계학자들은 확률을 사용해서 추정량의 특징들을 characterize하는 방법에 능숙하다. 즉, 추정량 자체의 행태가 판단하기 힘들다 할지라도 - 그것이 '대부분' 어떻게 행동하는지에 대한 도구들. 가능하다면, '메져 0인 상황을 제외하고는' 모두 이렇게 행동할 것이다-에 대한 기준을 제시하는 일들. 즉, 어떤 추정량이 대부분, 혹은 진짜 거의 확실하게 어떻게 행동할 것인가를 characterize하는 일들.

(2) (두번쨰는 방금 까먹음 미친.. 치맨가)

-

내가 느끼기에 통계학은 수학보다는 사회과학에 가깝다. 즉 수치들을 어떻게 인간의 언어로 해석할지, 거꾸로 인간의 언어에 해당하는 수치들을 어떻게 구성할지 이런 것들이 통계학의 핵심이다. 

그래서 내가 느끼는 최근의 긴장은 머신러닝과 통계학 사이의 관계에 대한 것이다. 즉 인간의 해석이 필요하지 않은 블랙박스 모델이 기존의 수학적 모델들보다도 더 좋은 퍼포먼스를 보일 때 통계학에서는 어떤 말을 할 수 있나? 
아니면 통계학이라는 필드를 고수하는 게 - 즉 모델을 인간의 언어로 구성하고 해석하는 데 매달리는 게 - 어쩌면 outdated된 건 아닌가 마치 개항기에 성리학을 고수하는 일처럼?

내가 가진 희미한 직관은 semiparametric efficiency이다. 즉 모델이라는 것의 robustness이 여전히 중요한 논점이라면, 또 나아가서 그 robustness를 무한차원의 nuisance parameter로 형상화하는 게 효율적인 일이 맞다면 그렇다면 doubly robust machine learning이라는 일을 통해 통계학이 할 수 있는 일이 여전히 있을 것만 같다.. 내 머리가 이것들을 이해할 수 있는지와는 별개로.




